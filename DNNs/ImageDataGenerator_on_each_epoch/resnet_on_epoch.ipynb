{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" <span style=\"font-size:28px;\"> **SKIN LESION CLASSIFICATION - DENSENET-201 + IMAGEDATAGENERATOR ON EACH EPOCH.** </span>\n\n\nThe HAM10000 dataset has 7 different classes of skin lesion which are listed below :\n1. Melanocytic nevi\n2. Melanoma\n3. Benign keratosis-like lesions\n4. Basal cell carcinoma\n5. Actinic keratoses\n6. Vascular lesions\n7. Dermatofibroma","metadata":{}},{"cell_type":"markdown","source":" <span style=\"font-size:28px;\"> **Importing and Installing Essential Libraries.** </span>","metadata":{}},{"cell_type":"code","source":"from numpy.random import seed\nseed(101)\nimport tensorflow as tf\ntf.random.set_seed(101)\n\nimport tensorflowjs as tfjs\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten\n\n\nimport pandas as pd\nimport numpy as np\n#import keras\n#from keras import backend as K\n\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import ResNet50\nimport os\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:02:52.923161Z","iopub.execute_input":"2024-01-13T10:02:52.924670Z","iopub.status.idle":"2024-01-13T10:03:09.597470Z","shell.execute_reply.started":"2024-01-13T10:02:52.924626Z","shell.execute_reply":"2024-01-13T10:03:09.596346Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Directory Structure\n\nWe create folders to store images that will later be fed to Keras generators","metadata":{}},{"cell_type":"code","source":"base_dir = 'base_dir'\nos.mkdir(base_dir)\n\n# create a path to 'base_dir' to which we will join the names of the new folders\n# train_dir\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\n# val_dir\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\ntest_dir = os.path.join(base_dir, 'test_dir')\nos.mkdir(test_dir)\n\n# create new folders inside train_dir\nnv = os.path.join(train_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(train_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(train_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(train_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(train_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(train_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(train_dir, 'df')\nos.mkdir(df)\n\n# create new folders inside val_dir\nnv = os.path.join(val_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(val_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(val_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(val_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(val_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(val_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(val_dir, 'df')\nos.mkdir(df)\n\n\n# create new folders inside test_dir\nnv = os.path.join(test_dir, 'nv')\nos.mkdir(nv)\nmel = os.path.join(test_dir, 'mel')\nos.mkdir(mel)\nbkl = os.path.join(test_dir, 'bkl')\nos.mkdir(bkl)\nbcc = os.path.join(test_dir, 'bcc')\nos.mkdir(bcc)\nakiec = os.path.join(test_dir, 'akiec')\nos.mkdir(akiec)\nvasc = os.path.join(test_dir, 'vasc')\nos.mkdir(vasc)\ndf = os.path.join(test_dir, 'df')\nos.mkdir(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_data = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\ndf_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:03:09.695984Z","iopub.execute_input":"2024-01-13T10:03:09.696727Z","iopub.status.idle":"2024-01-13T10:03:09.743081Z","shell.execute_reply.started":"2024-01-13T10:03:09.696684Z","shell.execute_reply":"2024-01-13T10:03:09.741897Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     lesion_id      image_id   dx dx_type   age   sex localization\n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lesion_id</th>\n      <th>image_id</th>\n      <th>dx</th>\n      <th>dx_type</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>localization</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HAM_0000118</td>\n      <td>ISIC_0027419</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HAM_0000118</td>\n      <td>ISIC_0025030</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HAM_0002730</td>\n      <td>ISIC_0026769</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HAM_0002730</td>\n      <td>ISIC_0025661</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HAM_0001466</td>\n      <td>ISIC_0031633</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>75.0</td>\n      <td>male</td>\n      <td>ear</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# How many images in each class on HAM10000 dataset\ndf_data['dx'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:03:49.283708Z","iopub.execute_input":"2024-01-13T10:03:49.284243Z","iopub.status.idle":"2024-01-13T10:03:49.301855Z","shell.execute_reply.started":"2024-01-13T10:03:49.284199Z","shell.execute_reply":"2024-01-13T10:03:49.300711Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"dx\nnv       6705\nmel      1113\nbkl      1099\nbcc       514\nakiec     327\nvasc      142\ndf        115\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#X = df_data.drop('dx', axis=1)\ny = df_data['dx']\n\ndf_train, df_test = train_test_split(df_data, test_size=0.1, random_state=42, stratify=y)\n\nprint(df_train.shape)\nprint(df_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:03:52.342012Z","iopub.execute_input":"2024-01-13T10:03:52.342444Z","iopub.status.idle":"2024-01-13T10:03:52.369401Z","shell.execute_reply.started":"2024-01-13T10:03:52.342410Z","shell.execute_reply":"2024-01-13T10:03:52.367453Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(9013, 7)\n(1002, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"y = df_train['dx']\n\ndf_train, df_val = train_test_split(df_train, test_size=0.1, random_state=42, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(8111, 7)\n(902, 7)\n","output_type":"stream"}]},{"cell_type":"code","source":"#How many image each class in train set?\ndf_train['dx'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:04:19.018378Z","iopub.execute_input":"2024-01-13T10:04:19.019433Z","iopub.status.idle":"2024-01-13T10:04:19.029330Z","shell.execute_reply.started":"2024-01-13T10:04:19.019390Z","shell.execute_reply":"2024-01-13T10:04:19.028260Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"dx\nnv       5430\nmel       902\nbkl       890\nbcc       417\nakiec     264\nvasc      115\ndf         93\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#How many image each class in val set?\ndf_val['dx'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:05:05.769378Z","iopub.execute_input":"2024-01-13T10:05:05.769894Z","iopub.status.idle":"2024-01-13T10:05:05.780377Z","shell.execute_reply.started":"2024-01-13T10:05:05.769851Z","shell.execute_reply":"2024-01-13T10:05:05.779513Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"dx\nnv       604\nmel      100\nbkl       99\nbcc       46\nakiec     30\nvasc      13\ndf        10\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#How many image each class in test set?\ndf_test['dx'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:05:12.338037Z","iopub.execute_input":"2024-01-13T10:05:12.338422Z","iopub.status.idle":"2024-01-13T10:05:12.347627Z","shell.execute_reply.started":"2024-01-13T10:05:12.338393Z","shell.execute_reply":"2024-01-13T10:05:12.346534Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"dx\nnv       671\nmel      111\nbkl      110\nbcc       51\nakiec     33\nvasc      14\ndf        12\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Now we will transfer the images into the created subfolders","metadata":{}},{"cell_type":"code","source":"# Set the image_id as the index in df_data\ndf_data.set_index('image_id', inplace=True, drop=False)\ndf_data","metadata":{"execution":{"iopub.status.busy":"2023-12-31T06:28:53.237198Z","iopub.execute_input":"2023-12-31T06:28:53.237853Z","iopub.status.idle":"2023-12-31T06:28:53.254166Z","shell.execute_reply.started":"2023-12-31T06:28:53.237819Z","shell.execute_reply":"2023-12-31T06:28:53.253141Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                lesion_id      image_id     dx dx_type   age     sex  \\\nimage_id                                                               \nISIC_0027419  HAM_0000118  ISIC_0027419    bkl   histo  80.0    male   \nISIC_0025030  HAM_0000118  ISIC_0025030    bkl   histo  80.0    male   \nISIC_0026769  HAM_0002730  ISIC_0026769    bkl   histo  80.0    male   \nISIC_0025661  HAM_0002730  ISIC_0025661    bkl   histo  80.0    male   \nISIC_0031633  HAM_0001466  ISIC_0031633    bkl   histo  75.0    male   \n...                   ...           ...    ...     ...   ...     ...   \nISIC_0033084  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male   \nISIC_0033550  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male   \nISIC_0033536  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male   \nISIC_0032854  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male   \nISIC_0032258  HAM_0003521  ISIC_0032258    mel   histo  70.0  female   \n\n             localization  \nimage_id                   \nISIC_0027419        scalp  \nISIC_0025030        scalp  \nISIC_0026769        scalp  \nISIC_0025661        scalp  \nISIC_0031633          ear  \n...                   ...  \nISIC_0033084      abdomen  \nISIC_0033550      abdomen  \nISIC_0033536      abdomen  \nISIC_0032854         face  \nISIC_0032258         back  \n\n[10015 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>lesion_id</th>\n      <th>image_id</th>\n      <th>dx</th>\n      <th>dx_type</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>localization</th>\n    </tr>\n    <tr>\n      <th>image_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ISIC_0027419</th>\n      <td>HAM_0000118</td>\n      <td>ISIC_0027419</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n    </tr>\n    <tr>\n      <th>ISIC_0025030</th>\n      <td>HAM_0000118</td>\n      <td>ISIC_0025030</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n    </tr>\n    <tr>\n      <th>ISIC_0026769</th>\n      <td>HAM_0002730</td>\n      <td>ISIC_0026769</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n    </tr>\n    <tr>\n      <th>ISIC_0025661</th>\n      <td>HAM_0002730</td>\n      <td>ISIC_0025661</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>scalp</td>\n    </tr>\n    <tr>\n      <th>ISIC_0031633</th>\n      <td>HAM_0001466</td>\n      <td>ISIC_0031633</td>\n      <td>bkl</td>\n      <td>histo</td>\n      <td>75.0</td>\n      <td>male</td>\n      <td>ear</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>ISIC_0033084</th>\n      <td>HAM_0002867</td>\n      <td>ISIC_0033084</td>\n      <td>akiec</td>\n      <td>histo</td>\n      <td>40.0</td>\n      <td>male</td>\n      <td>abdomen</td>\n    </tr>\n    <tr>\n      <th>ISIC_0033550</th>\n      <td>HAM_0002867</td>\n      <td>ISIC_0033550</td>\n      <td>akiec</td>\n      <td>histo</td>\n      <td>40.0</td>\n      <td>male</td>\n      <td>abdomen</td>\n    </tr>\n    <tr>\n      <th>ISIC_0033536</th>\n      <td>HAM_0002867</td>\n      <td>ISIC_0033536</td>\n      <td>akiec</td>\n      <td>histo</td>\n      <td>40.0</td>\n      <td>male</td>\n      <td>abdomen</td>\n    </tr>\n    <tr>\n      <th>ISIC_0032854</th>\n      <td>HAM_0000239</td>\n      <td>ISIC_0032854</td>\n      <td>akiec</td>\n      <td>histo</td>\n      <td>80.0</td>\n      <td>male</td>\n      <td>face</td>\n    </tr>\n    <tr>\n      <th>ISIC_0032258</th>\n      <td>HAM_0003521</td>\n      <td>ISIC_0032258</td>\n      <td>mel</td>\n      <td>histo</td>\n      <td>70.0</td>\n      <td>female</td>\n      <td>back</td>\n    </tr>\n  </tbody>\n</table>\n<p>10015 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Get a list of images in each of the two folders\nfolder_1 = os.listdir('../input/skin-cancer-mnist-ham10000/ham10000_images_part_1')\nfolder_2 = os.listdir('../input/skin-cancer-mnist-ham10000/ham10000_images_part_2')\n\n# Get a list of train and val images\ntrain_list = list(df_train['image_id'])\nval_list = list(df_val['image_id'])\ntest_list = list(df_test['image_id'])\n\n\n# Transfer the train images\n\nfor image in train_list:\n    \n    fname = image + '.jpg'\n    label = df_data.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(train_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n\n# Transfer the val images\n\nfor image in val_list:\n    \n    fname = image + '.jpg'\n    label = df_data.loc[image,'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(val_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n        \n        \nfor image in test_list:\n    \n    fname = image + '.jpg'\n    label = df_data.loc[image, 'dx']\n    \n    if fname in folder_1:\n        # source path to image\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_1', fname)\n        # destination path to image\n        dst = os.path.join(test_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)\n\n    if fname in folder_2:\n        # source path to image\n        src = os.path.join('../input/skin-cancer-mnist-ham10000/ham10000_images_part_2', fname)\n        # destination path to image\n        dst = os.path.join(test_dir, label, fname)\n        # copy the image from the source to the destination\n        shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T06:28:55.369641Z","iopub.execute_input":"2023-12-31T06:28:55.370003Z","iopub.status.idle":"2023-12-31T06:31:18.849098Z","shell.execute_reply.started":"2023-12-31T06:28:55.369973Z","shell.execute_reply":"2023-12-31T06:31:18.848220Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# check how many train images we have in each folder\n\nprint(len(os.listdir('base_dir/train_dir/nv')))\nprint(len(os.listdir('base_dir/train_dir/mel')))\nprint(len(os.listdir('base_dir/train_dir/bkl')))\nprint(len(os.listdir('base_dir/train_dir/bcc')))\nprint(len(os.listdir('base_dir/train_dir/akiec')))\nprint(len(os.listdir('base_dir/train_dir/vasc')))\nprint(len(os.listdir('base_dir/train_dir/df')))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:05:32.627224Z","iopub.execute_input":"2024-01-13T10:05:32.627904Z","iopub.status.idle":"2024-01-13T10:05:32.647105Z","shell.execute_reply.started":"2024-01-13T10:05:32.627863Z","shell.execute_reply":"2024-01-13T10:05:32.645490Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"5430\n902\n890\n417\n264\n115\n93\n","output_type":"stream"}]},{"cell_type":"code","source":"# check how many val images we have in each folder\n\nprint(len(os.listdir('base_dir/val_dir/nv')))\nprint(len(os.listdir('base_dir/val_dir/mel')))\nprint(len(os.listdir('base_dir/val_dir/bkl')))\nprint(len(os.listdir('base_dir/val_dir/bcc')))\nprint(len(os.listdir('base_dir/val_dir/akiec')))\nprint(len(os.listdir('base_dir/val_dir/vasc')))\nprint(len(os.listdir('base_dir/val_dir/df')))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:05:34.203152Z","iopub.execute_input":"2024-01-13T10:05:34.203586Z","iopub.status.idle":"2024-01-13T10:05:34.212271Z","shell.execute_reply.started":"2024-01-13T10:05:34.203552Z","shell.execute_reply":"2024-01-13T10:05:34.211081Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"604\n100\n99\n46\n30\n13\n10\n","output_type":"stream"}]},{"cell_type":"code","source":"# check how many val images we have in each folder\n\nprint(len(os.listdir('base_dir/test_dir/nv')))\nprint(len(os.listdir('base_dir/test_dir/mel')))\nprint(len(os.listdir('base_dir/test_dir/bkl')))\nprint(len(os.listdir('base_dir/test_dir/bcc')))\nprint(len(os.listdir('base_dir/test_dir/akiec')))\nprint(len(os.listdir('base_dir/test_dir/vasc')))\nprint(len(os.listdir('base_dir/test_dir/df')))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:05:36.811246Z","iopub.execute_input":"2024-01-13T10:05:36.811656Z","iopub.status.idle":"2024-01-13T10:05:36.821218Z","shell.execute_reply.started":"2024-01-13T10:05:36.811625Z","shell.execute_reply":"2024-01-13T10:05:36.819884Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"671\n111\n110\n51\n33\n14\n12\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = 'base_dir/train_dir'\nvalid_path = 'base_dir/val_dir'\ntest_path = 'base_dir/test_dir'\n\nnum_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = 32\nval_batch_size = 4\nimage_size = 224\n\ntrain_steps = np.ceil(num_train_samples / train_batch_size)\nval_steps = np.ceil(num_val_samples / val_batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:05:41.749951Z","iopub.execute_input":"2024-01-13T10:05:41.750392Z","iopub.status.idle":"2024-01-13T10:05:41.757369Z","shell.execute_reply.started":"2024-01-13T10:05:41.750358Z","shell.execute_reply":"2024-01-13T10:05:41.756044Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# ImageDataGenerator on each Epoch","metadata":{}},{"cell_type":"code","source":"datagen_train = ImageDataGenerator(\n        rotation_range=180,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=True,\n        #brightness_range=(0.9,1.1),\n        fill_mode='nearest',\n        preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n)\n\ntrain_batches = datagen_train.flow_from_directory(\n    train_path,\n    target_size=(image_size, image_size),\n    batch_size=train_batch_size\n)\n\nvalid_batches = datagen_train.flow_from_directory(\n    valid_path,\n    target_size=(image_size, image_size),\n    batch_size=val_batch_size\n)\n\ndatagen = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.resnet50.preprocess_input\n)\ntest_batches = datagen.flow_from_directory(\n    test_path,\n    target_size=(image_size, image_size),\n    batch_size=1,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:08:12.883746Z","iopub.execute_input":"2024-01-13T10:08:12.884168Z","iopub.status.idle":"2024-01-13T10:08:13.383347Z","shell.execute_reply.started":"2024-01-13T10:08:12.884136Z","shell.execute_reply":"2024-01-13T10:08:13.382377Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Found 8111 images belonging to 7 classes.\nFound 902 images belonging to 7 classes.\nFound 1002 images belonging to 7 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\npre_trained_model = ResNet50(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:06:14.152740Z","iopub.execute_input":"2024-01-13T10:06:14.153182Z","iopub.status.idle":"2024-01-13T10:06:21.348588Z","shell.execute_reply.started":"2024-01-13T10:06:14.153146Z","shell.execute_reply":"2024-01-13T10:06:21.347401Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94765736/94765736 [==============================] - 4s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"pre_trained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:06:21.802468Z","iopub.execute_input":"2024-01-13T10:06:21.802883Z","iopub.status.idle":"2024-01-13T10:06:22.405128Z","shell.execute_reply.started":"2024-01-13T10:06:21.802847Z","shell.execute_reply":"2024-01-13T10:06:22.403993Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Model: \"resnet50\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n                                                                                                  \n conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_1[0][0]']             \n                                                                                                  \n conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n                                                                                                  \n conv1_bn (BatchNormalizati  (None, 112, 112, 64)         256       ['conv1_conv[0][0]']          \n on)                                                                                              \n                                                                                                  \n conv1_relu (Activation)     (None, 112, 112, 64)         0         ['conv1_bn[0][0]']            \n                                                                                                  \n pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_relu[0][0]']          \n                                                                                                  \n pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n                                                                                                  \n conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4160      ['pool1_pool[0][0]']          \n D)                                                                                               \n                                                                                                  \n conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['pool1_pool[0][0]']          \n D)                                                                                               \n                                                                                                  \n conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block1_0_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_bn[0][0]',   \n                                                                     'conv2_block1_3_bn[0][0]']   \n                                                                                                  \n conv2_block1_out (Activati  (None, 56, 56, 256)          0         ['conv2_block1_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block1_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block2_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block2_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n                                                                     'conv2_block2_3_bn[0][0]']   \n                                                                                                  \n conv2_block2_out (Activati  (None, 56, 56, 256)          0         ['conv2_block2_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block3_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block3_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block3_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block3_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block3_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block3_add (Add)      (None, 56, 56, 256)          0         ['conv2_block2_out[0][0]',    \n                                                                     'conv2_block3_3_bn[0][0]']   \n                                                                                                  \n conv2_block3_out (Activati  (None, 56, 56, 256)          0         ['conv2_block3_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32896     ['conv2_block3_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv2_block3_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block1_0_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_bn[0][0]',   \n                                                                     'conv3_block1_3_bn[0][0]']   \n                                                                                                  \n conv3_block1_out (Activati  (None, 28, 28, 512)          0         ['conv3_block1_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block1_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block2_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block2_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n                                                                     'conv3_block2_3_bn[0][0]']   \n                                                                                                  \n conv3_block2_out (Activati  (None, 28, 28, 512)          0         ['conv3_block2_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block3_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block3_add (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n                                                                     'conv3_block3_3_bn[0][0]']   \n                                                                                                  \n conv3_block3_out (Activati  (None, 28, 28, 512)          0         ['conv3_block3_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block3_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block4_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block4_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block4_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block4_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block4_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block4_add (Add)      (None, 28, 28, 512)          0         ['conv3_block3_out[0][0]',    \n                                                                     'conv3_block4_3_bn[0][0]']   \n                                                                                                  \n conv3_block4_out (Activati  (None, 28, 28, 512)          0         ['conv3_block4_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131328    ['conv3_block4_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv3_block4_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block1_0_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n                                                                     'conv4_block1_3_bn[0][0]']   \n                                                                                                  \n conv4_block1_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block1_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block1_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block2_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block2_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n                                                                     'conv4_block2_3_bn[0][0]']   \n                                                                                                  \n conv4_block2_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block2_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block3_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block3_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n                                                                     'conv4_block3_3_bn[0][0]']   \n                                                                                                  \n conv4_block3_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block3_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block3_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block4_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block4_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n                                                                     'conv4_block4_3_bn[0][0]']   \n                                                                                                  \n conv4_block4_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block4_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block4_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block5_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block5_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n                                                                     'conv4_block5_3_bn[0][0]']   \n                                                                                                  \n conv4_block5_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block5_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block5_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block6_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block6_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block6_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block6_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block6_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block6_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block5_out[0][0]',    \n                                                                     'conv4_block6_3_bn[0][0]']   \n                                                                                                  \n conv4_block6_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block6_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524800    ['conv4_block6_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv4_block6_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block1_0_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n                                                                     'conv5_block1_3_bn[0][0]']   \n                                                                                                  \n conv5_block1_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block1_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block1_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block2_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block2_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n                                                                     'conv5_block2_3_bn[0][0]']   \n                                                                                                  \n conv5_block2_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block2_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block3_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block3_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n                                                                     'conv5_block3_3_bn[0][0]']   \n                                                                                                  \n conv5_block3_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block3_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n==================================================================================================\nTotal params: 23587712 (89.98 MB)\nTrainable params: 23534592 (89.78 MB)\nNon-trainable params: 53120 (207.50 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"last_layer = pre_trained_model.get_layer('conv5_block3_out')\nprint('Last layer output shape:', last_layer.output_shape)\nlast_output = last_layer.output","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:06:25.777284Z","iopub.execute_input":"2024-01-13T10:06:25.777749Z","iopub.status.idle":"2024-01-13T10:06:25.784808Z","shell.execute_reply.started":"2024-01-13T10:06:25.777705Z","shell.execute_reply":"2024-01-13T10:06:25.783909Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Last layer output shape: (None, 7, 7, 2048)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Flatten the output layer to 1 dimension\nx = GlobalAveragePooling2D()(last_output)\n# Add a fully connected layer with 512 hidden units and ReLU activation\nx = Dense(512, activation='relu')(x)\n# Add a dropout rate of 0.7\nx = Dropout(0.3)(x)\n# Add a final sigmoid layer for classification\nx = Dense(7, activation='softmax')(x)\n\n# Configure and compile the model\n\nmodel = Model(pre_trained_model.input, x)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:06:54.147845Z","iopub.execute_input":"2024-01-13T10:06:54.148302Z","iopub.status.idle":"2024-01-13T10:06:54.222031Z","shell.execute_reply.started":"2024-01-13T10:06:54.148267Z","shell.execute_reply":"2024-01-13T10:06:54.220667Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:06:57.643293Z","iopub.execute_input":"2024-01-13T10:06:57.643857Z","iopub.status.idle":"2024-01-13T10:06:58.295128Z","shell.execute_reply.started":"2024-01-13T10:06:57.643810Z","shell.execute_reply":"2024-01-13T10:06:58.291376Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n                                                                                                  \n conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_1[0][0]']             \n                                                                                                  \n conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n                                                                                                  \n conv1_bn (BatchNormalizati  (None, 112, 112, 64)         256       ['conv1_conv[0][0]']          \n on)                                                                                              \n                                                                                                  \n conv1_relu (Activation)     (None, 112, 112, 64)         0         ['conv1_bn[0][0]']            \n                                                                                                  \n pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_relu[0][0]']          \n                                                                                                  \n pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n                                                                                                  \n conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4160      ['pool1_pool[0][0]']          \n D)                                                                                               \n                                                                                                  \n conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['pool1_pool[0][0]']          \n D)                                                                                               \n                                                                                                  \n conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block1_0_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_bn[0][0]',   \n                                                                     'conv2_block1_3_bn[0][0]']   \n                                                                                                  \n conv2_block1_out (Activati  (None, 56, 56, 256)          0         ['conv2_block1_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block1_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block2_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block2_add (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n                                                                     'conv2_block2_3_bn[0][0]']   \n                                                                                                  \n conv2_block2_out (Activati  (None, 56, 56, 256)          0         ['conv2_block2_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16448     ['conv2_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block3_2_conv (Conv2  (None, 56, 56, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block3_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block3_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block3_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block3_3_bn (BatchNo  (None, 56, 56, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block3_add (Add)      (None, 56, 56, 256)          0         ['conv2_block2_out[0][0]',    \n                                                                     'conv2_block3_3_bn[0][0]']   \n                                                                                                  \n conv2_block3_out (Activati  (None, 56, 56, 256)          0         ['conv2_block3_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32896     ['conv2_block3_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv2_block3_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block1_0_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_bn[0][0]',   \n                                                                     'conv3_block1_3_bn[0][0]']   \n                                                                                                  \n conv3_block1_out (Activati  (None, 28, 28, 512)          0         ['conv3_block1_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block1_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block2_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block2_add (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n                                                                     'conv3_block2_3_bn[0][0]']   \n                                                                                                  \n conv3_block2_out (Activati  (None, 28, 28, 512)          0         ['conv3_block2_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block3_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block3_add (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n                                                                     'conv3_block3_3_bn[0][0]']   \n                                                                                                  \n conv3_block3_out (Activati  (None, 28, 28, 512)          0         ['conv3_block3_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65664     ['conv3_block3_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block4_2_conv (Conv2  (None, 28, 28, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block4_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block4_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block4_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block4_3_bn (BatchNo  (None, 28, 28, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block4_add (Add)      (None, 28, 28, 512)          0         ['conv3_block3_out[0][0]',    \n                                                                     'conv3_block4_3_bn[0][0]']   \n                                                                                                  \n conv3_block4_out (Activati  (None, 28, 28, 512)          0         ['conv3_block4_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131328    ['conv3_block4_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block1_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv3_block4_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block1_0_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_0_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block1_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_bn[0][0]',   \n                                                                     'conv4_block1_3_bn[0][0]']   \n                                                                                                  \n conv4_block1_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block1_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block1_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block2_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block2_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block2_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block2_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n                                                                     'conv4_block2_3_bn[0][0]']   \n                                                                                                  \n conv4_block2_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block2_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block3_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block3_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block3_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block3_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n                                                                     'conv4_block3_3_bn[0][0]']   \n                                                                                                  \n conv4_block3_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block3_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block3_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block4_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block4_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block4_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block4_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n                                                                     'conv4_block4_3_bn[0][0]']   \n                                                                                                  \n conv4_block4_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block4_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block4_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block5_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block5_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block5_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block5_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n                                                                     'conv4_block5_3_bn[0][0]']   \n                                                                                                  \n conv4_block5_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block5_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262400    ['conv4_block5_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block6_2_conv (Conv2  (None, 14, 14, 256)          590080    ['conv4_block6_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block6_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block6_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block6_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block6_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block6_3_bn (BatchNo  (None, 14, 14, 1024)         4096      ['conv4_block6_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block6_add (Add)      (None, 14, 14, 1024)         0         ['conv4_block5_out[0][0]',    \n                                                                     'conv4_block6_3_bn[0][0]']   \n                                                                                                  \n conv4_block6_out (Activati  (None, 14, 14, 1024)         0         ['conv4_block6_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524800    ['conv4_block6_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block1_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv4_block6_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block1_0_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_0_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block1_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_bn[0][0]',   \n                                                                     'conv5_block1_3_bn[0][0]']   \n                                                                                                  \n conv5_block1_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block1_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block1_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block2_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block2_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block2_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block2_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n                                                                     'conv5_block2_3_bn[0][0]']   \n                                                                                                  \n conv5_block2_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block2_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1049088   ['conv5_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359808   ['conv5_block3_1_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block3_3_bn (BatchNo  (None, 7, 7, 2048)           8192      ['conv5_block3_3_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block3_add (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n                                                                     'conv5_block3_3_bn[0][0]']   \n                                                                                                  \n conv5_block3_out (Activati  (None, 7, 7, 2048)           0         ['conv5_block3_add[0][0]']    \n on)                                                                                              \n                                                                                                  \n global_average_pooling2d (  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n dense (Dense)               (None, 512)                  1049088   ['global_average_pooling2d[0][\n                                                                    0]']                          \n                                                                                                  \n dropout (Dropout)           (None, 512)                  0         ['dense[0][0]']               \n                                                                                                  \n dense_1 (Dense)             (None, 7)                    3591      ['dropout[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 24640391 (94.00 MB)\nTrainable params: 24587271 (93.79 MB)\nNon-trainable params: 53120 (207.50 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:07:05.292146Z","iopub.execute_input":"2024-01-13T10:07:05.292542Z","iopub.status.idle":"2024-01-13T10:07:05.320474Z","shell.execute_reply.started":"2024-01-13T10:07:05.292511Z","shell.execute_reply":"2024-01-13T10:07:05.319539Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"filepath = \"model.h5\" #use recall\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose = 1,\n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=2,\n                                   verbose=1, mode='max', min_lr=0.0000001)\n\nEarlystop = EarlyStopping(monitor='val_loss', mode='min',patience=30, min_delta=0.001)\ncallbacks_list = [checkpoint, reduce_lr, Earlystop]\n\n\nhistory = model.fit(train_batches, steps_per_epoch=train_steps,\n                    validation_data=valid_batches,\n                    validation_steps=val_steps,\n                    epochs=150, verbose=1,\n                   callbacks=callbacks_list\n                   )","metadata":{"execution":{"iopub.status.busy":"2023-12-31T06:56:16.060642Z","iopub.execute_input":"2023-12-31T06:56:16.061320Z","iopub.status.idle":"2023-12-31T09:49:47.521507Z","shell.execute_reply.started":"2023-12-31T06:56:16.061286Z","shell.execute_reply":"2023-12-31T09:49:47.520732Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/150\n254/254 [==============================] - ETA: 0s - loss: 0.9645 - accuracy: 0.6881\nEpoch 1: val_accuracy improved from -inf to 0.67073, saving model to model.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"254/254 [==============================] - 207s 644ms/step - loss: 0.9645 - accuracy: 0.6881 - val_loss: 2.8000 - val_accuracy: 0.6707 - lr: 0.0010\nEpoch 2/150\n254/254 [==============================] - ETA: 0s - loss: 0.7846 - accuracy: 0.7177\nEpoch 2: val_accuracy improved from 0.67073 to 0.71064, saving model to model.h5\n254/254 [==============================] - 163s 640ms/step - loss: 0.7846 - accuracy: 0.7177 - val_loss: 6.7671 - val_accuracy: 0.7106 - lr: 0.0010\nEpoch 3/150\n254/254 [==============================] - ETA: 0s - loss: 0.7463 - accuracy: 0.7343\nEpoch 3: val_accuracy did not improve from 0.71064\n254/254 [==============================] - 161s 634ms/step - loss: 0.7463 - accuracy: 0.7343 - val_loss: 1.0824 - val_accuracy: 0.5765 - lr: 0.0010\nEpoch 4/150\n254/254 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.7404\nEpoch 4: val_accuracy did not improve from 0.71064\n\nEpoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n254/254 [==============================] - 163s 640ms/step - loss: 0.6967 - accuracy: 0.7404 - val_loss: 1.3199 - val_accuracy: 0.6186 - lr: 0.0010\nEpoch 5/150\n254/254 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.7646\nEpoch 5: val_accuracy improved from 0.71064 to 0.75166, saving model to model.h5\n254/254 [==============================] - 164s 646ms/step - loss: 0.6361 - accuracy: 0.7646 - val_loss: 0.6545 - val_accuracy: 0.7517 - lr: 5.0000e-04\nEpoch 6/150\n254/254 [==============================] - ETA: 0s - loss: 0.5988 - accuracy: 0.7765\nEpoch 6: val_accuracy improved from 0.75166 to 0.77384, saving model to model.h5\n254/254 [==============================] - 163s 643ms/step - loss: 0.5988 - accuracy: 0.7765 - val_loss: 0.6833 - val_accuracy: 0.7738 - lr: 5.0000e-04\nEpoch 7/150\n254/254 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.7757\nEpoch 7: val_accuracy did not improve from 0.77384\n254/254 [==============================] - 162s 635ms/step - loss: 0.6088 - accuracy: 0.7757 - val_loss: 0.6566 - val_accuracy: 0.7583 - lr: 5.0000e-04\nEpoch 8/150\n254/254 [==============================] - ETA: 0s - loss: 0.5932 - accuracy: 0.7813\nEpoch 8: val_accuracy did not improve from 0.77384\n\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n254/254 [==============================] - 161s 634ms/step - loss: 0.5932 - accuracy: 0.7813 - val_loss: 0.6377 - val_accuracy: 0.7627 - lr: 5.0000e-04\nEpoch 9/150\n254/254 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.7930\nEpoch 9: val_accuracy improved from 0.77384 to 0.79379, saving model to model.h5\n254/254 [==============================] - 161s 634ms/step - loss: 0.5455 - accuracy: 0.7930 - val_loss: 0.5824 - val_accuracy: 0.7938 - lr: 2.5000e-04\nEpoch 10/150\n254/254 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.8032\nEpoch 10: val_accuracy did not improve from 0.79379\n254/254 [==============================] - 160s 631ms/step - loss: 0.5302 - accuracy: 0.8032 - val_loss: 0.6342 - val_accuracy: 0.7849 - lr: 2.5000e-04\nEpoch 11/150\n254/254 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8104\nEpoch 11: val_accuracy did not improve from 0.79379\n\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n254/254 [==============================] - 160s 629ms/step - loss: 0.5061 - accuracy: 0.8104 - val_loss: 0.5552 - val_accuracy: 0.7927 - lr: 2.5000e-04\nEpoch 12/150\n254/254 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.8188\nEpoch 12: val_accuracy improved from 0.79379 to 0.80599, saving model to model.h5\n254/254 [==============================] - 162s 636ms/step - loss: 0.4818 - accuracy: 0.8188 - val_loss: 0.5426 - val_accuracy: 0.8060 - lr: 1.2500e-04\nEpoch 13/150\n254/254 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.8274\nEpoch 13: val_accuracy did not improve from 0.80599\n254/254 [==============================] - 159s 627ms/step - loss: 0.4604 - accuracy: 0.8274 - val_loss: 0.5342 - val_accuracy: 0.8049 - lr: 1.2500e-04\nEpoch 14/150\n254/254 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.8270\nEpoch 14: val_accuracy did not improve from 0.80599\n\nEpoch 14: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n254/254 [==============================] - 160s 628ms/step - loss: 0.4576 - accuracy: 0.8270 - val_loss: 0.5491 - val_accuracy: 0.8027 - lr: 1.2500e-04\nEpoch 15/150\n254/254 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.8412\nEpoch 15: val_accuracy improved from 0.80599 to 0.81596, saving model to model.h5\n254/254 [==============================] - 161s 633ms/step - loss: 0.4237 - accuracy: 0.8412 - val_loss: 0.4953 - val_accuracy: 0.8160 - lr: 6.2500e-05\nEpoch 16/150\n254/254 [==============================] - ETA: 0s - loss: 0.4148 - accuracy: 0.8448\nEpoch 16: val_accuracy improved from 0.81596 to 0.82262, saving model to model.h5\n254/254 [==============================] - 162s 639ms/step - loss: 0.4148 - accuracy: 0.8448 - val_loss: 0.4872 - val_accuracy: 0.8226 - lr: 6.2500e-05\nEpoch 17/150\n254/254 [==============================] - ETA: 0s - loss: 0.4014 - accuracy: 0.8459\nEpoch 17: val_accuracy did not improve from 0.82262\n254/254 [==============================] - 160s 631ms/step - loss: 0.4014 - accuracy: 0.8459 - val_loss: 0.4948 - val_accuracy: 0.8193 - lr: 6.2500e-05\nEpoch 18/150\n254/254 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8493\nEpoch 18: val_accuracy did not improve from 0.82262\n\nEpoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n254/254 [==============================] - 159s 627ms/step - loss: 0.3946 - accuracy: 0.8493 - val_loss: 0.5121 - val_accuracy: 0.8226 - lr: 6.2500e-05\nEpoch 19/150\n254/254 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.8586\nEpoch 19: val_accuracy improved from 0.82262 to 0.83259, saving model to model.h5\n254/254 [==============================] - 161s 635ms/step - loss: 0.3833 - accuracy: 0.8586 - val_loss: 0.4659 - val_accuracy: 0.8326 - lr: 3.1250e-05\nEpoch 20/150\n254/254 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8618\nEpoch 20: val_accuracy did not improve from 0.83259\n254/254 [==============================] - 159s 626ms/step - loss: 0.3700 - accuracy: 0.8618 - val_loss: 0.4820 - val_accuracy: 0.8304 - lr: 3.1250e-05\nEpoch 21/150\n254/254 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.8661\nEpoch 21: val_accuracy did not improve from 0.83259\n\nEpoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n254/254 [==============================] - 160s 628ms/step - loss: 0.3545 - accuracy: 0.8661 - val_loss: 0.4884 - val_accuracy: 0.8304 - lr: 3.1250e-05\nEpoch 22/150\n254/254 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.8735\nEpoch 22: val_accuracy did not improve from 0.83259\n254/254 [==============================] - 160s 629ms/step - loss: 0.3423 - accuracy: 0.8735 - val_loss: 0.4715 - val_accuracy: 0.8326 - lr: 1.5625e-05\nEpoch 23/150\n254/254 [==============================] - ETA: 0s - loss: 0.3337 - accuracy: 0.8735\nEpoch 23: val_accuracy improved from 0.83259 to 0.83814, saving model to model.h5\n254/254 [==============================] - 161s 634ms/step - loss: 0.3337 - accuracy: 0.8735 - val_loss: 0.4715 - val_accuracy: 0.8381 - lr: 1.5625e-05\nEpoch 24/150\n254/254 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8754\nEpoch 24: val_accuracy improved from 0.83814 to 0.84590, saving model to model.h5\n254/254 [==============================] - 160s 631ms/step - loss: 0.3322 - accuracy: 0.8754 - val_loss: 0.4653 - val_accuracy: 0.8459 - lr: 1.5625e-05\nEpoch 25/150\n254/254 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.8791\nEpoch 25: val_accuracy did not improve from 0.84590\n254/254 [==============================] - 158s 623ms/step - loss: 0.3281 - accuracy: 0.8791 - val_loss: 0.4738 - val_accuracy: 0.8381 - lr: 1.5625e-05\nEpoch 26/150\n254/254 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.8767\nEpoch 26: val_accuracy did not improve from 0.84590\n\nEpoch 26: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n254/254 [==============================] - 159s 625ms/step - loss: 0.3233 - accuracy: 0.8767 - val_loss: 0.4795 - val_accuracy: 0.8304 - lr: 1.5625e-05\nEpoch 27/150\n254/254 [==============================] - ETA: 0s - loss: 0.3199 - accuracy: 0.8800\nEpoch 27: val_accuracy did not improve from 0.84590\n254/254 [==============================] - 158s 622ms/step - loss: 0.3199 - accuracy: 0.8800 - val_loss: 0.4788 - val_accuracy: 0.8415 - lr: 7.8125e-06\nEpoch 28/150\n254/254 [==============================] - ETA: 0s - loss: 0.3101 - accuracy: 0.8829\nEpoch 28: val_accuracy did not improve from 0.84590\n\nEpoch 28: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n254/254 [==============================] - 160s 631ms/step - loss: 0.3101 - accuracy: 0.8829 - val_loss: 0.4657 - val_accuracy: 0.8315 - lr: 7.8125e-06\nEpoch 29/150\n254/254 [==============================] - ETA: 0s - loss: 0.3096 - accuracy: 0.8802\nEpoch 29: val_accuracy did not improve from 0.84590\n254/254 [==============================] - 159s 624ms/step - loss: 0.3096 - accuracy: 0.8802 - val_loss: 0.4561 - val_accuracy: 0.8404 - lr: 3.9063e-06\nEpoch 30/150\n254/254 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.8860\nEpoch 30: val_accuracy did not improve from 0.84590\n\nEpoch 30: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n254/254 [==============================] - 159s 626ms/step - loss: 0.3057 - accuracy: 0.8860 - val_loss: 0.4636 - val_accuracy: 0.8392 - lr: 3.9063e-06\nEpoch 31/150\n254/254 [==============================] - ETA: 0s - loss: 0.3074 - accuracy: 0.8840\nEpoch 31: val_accuracy did not improve from 0.84590\n254/254 [==============================] - 159s 626ms/step - loss: 0.3074 - accuracy: 0.8840 - val_loss: 0.4615 - val_accuracy: 0.8392 - lr: 1.9531e-06\nEpoch 32/150\n254/254 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.8877\nEpoch 32: val_accuracy did not improve from 0.84590\n\nEpoch 32: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n254/254 [==============================] - 159s 626ms/step - loss: 0.3014 - accuracy: 0.8877 - val_loss: 0.4592 - val_accuracy: 0.8381 - lr: 1.9531e-06\nEpoch 33/150\n254/254 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.8848\nEpoch 33: val_accuracy did not improve from 0.84590\n254/254 [==============================] - 160s 628ms/step - loss: 0.2999 - accuracy: 0.8848 - val_loss: 0.4633 - val_accuracy: 0.8381 - lr: 9.7656e-07\nEpoch 34/150\n254/254 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8868\nEpoch 34: val_accuracy did not improve from 0.84590\n\nEpoch 34: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n254/254 [==============================] - 158s 621ms/step - loss: 0.2982 - accuracy: 0.8868 - val_loss: 0.4667 - val_accuracy: 0.8337 - lr: 9.7656e-07\nEpoch 35/150\n254/254 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.8877\nEpoch 35: val_accuracy did not improve from 0.84590\n254/254 [==============================] - 160s 628ms/step - loss: 0.2976 - accuracy: 0.8877 - val_loss: 0.4485 - val_accuracy: 0.8359 - lr: 4.8828e-07\nEpoch 36/150\n254/254 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8837\nEpoch 36: val_accuracy did not improve from 0.84590\n\nEpoch 36: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n254/254 [==============================] - 159s 625ms/step - loss: 0.3068 - accuracy: 0.8837 - val_loss: 0.4750 - val_accuracy: 0.8304 - lr: 4.8828e-07\nEpoch 37/150\n254/254 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.8836\nEpoch 37: val_accuracy did not improve from 0.84590\n254/254 [==============================] - 159s 624ms/step - loss: 0.3014 - accuracy: 0.8836 - val_loss: 0.4662 - val_accuracy: 0.8215 - lr: 2.4414e-07\nEpoch 38/150\n254/254 [==============================] - ETA: 0s - loss: 0.3016 - accuracy: 0.8852\nEpoch 38: val_accuracy improved from 0.84590 to 0.84812, saving model to model.h5\n254/254 [==============================] - 160s 628ms/step - loss: 0.3016 - accuracy: 0.8852 - val_loss: 0.4527 - val_accuracy: 0.8481 - lr: 2.4414e-07\nEpoch 39/150\n254/254 [==============================] - ETA: 0s - loss: 0.2998 - accuracy: 0.8874\nEpoch 39: val_accuracy did not improve from 0.84812\n254/254 [==============================] - 159s 625ms/step - loss: 0.2998 - accuracy: 0.8874 - val_loss: 0.4491 - val_accuracy: 0.8437 - lr: 2.4414e-07\nEpoch 40/150\n254/254 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.8853\nEpoch 40: val_accuracy did not improve from 0.84812\n\nEpoch 40: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n254/254 [==============================] - 159s 624ms/step - loss: 0.2963 - accuracy: 0.8853 - val_loss: 0.4730 - val_accuracy: 0.8381 - lr: 2.4414e-07\nEpoch 41/150\n254/254 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8866\nEpoch 41: val_accuracy did not improve from 0.84812\n254/254 [==============================] - 159s 624ms/step - loss: 0.2983 - accuracy: 0.8866 - val_loss: 0.4706 - val_accuracy: 0.8392 - lr: 1.2207e-07\nEpoch 42/150\n254/254 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.8853\nEpoch 42: val_accuracy did not improve from 0.84812\n\nEpoch 42: ReduceLROnPlateau reducing learning rate to 1e-07.\n254/254 [==============================] - 158s 623ms/step - loss: 0.3023 - accuracy: 0.8853 - val_loss: 0.4726 - val_accuracy: 0.8392 - lr: 1.2207e-07\nEpoch 43/150\n254/254 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8892\nEpoch 43: val_accuracy did not improve from 0.84812\n254/254 [==============================] - 158s 621ms/step - loss: 0.2982 - accuracy: 0.8892 - val_loss: 0.4800 - val_accuracy: 0.8370 - lr: 1.0000e-07\nEpoch 44/150\n254/254 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.8871\nEpoch 44: val_accuracy improved from 0.84812 to 0.85255, saving model to model.h5\n254/254 [==============================] - 160s 630ms/step - loss: 0.3001 - accuracy: 0.8871 - val_loss: 0.4705 - val_accuracy: 0.8525 - lr: 1.0000e-07\nEpoch 45/150\n254/254 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.8839\nEpoch 45: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 159s 626ms/step - loss: 0.3077 - accuracy: 0.8839 - val_loss: 0.4663 - val_accuracy: 0.8359 - lr: 1.0000e-07\nEpoch 46/150\n254/254 [==============================] - ETA: 0s - loss: 0.3002 - accuracy: 0.8899\nEpoch 46: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 622ms/step - loss: 0.3002 - accuracy: 0.8899 - val_loss: 0.4728 - val_accuracy: 0.8459 - lr: 1.0000e-07\nEpoch 47/150\n254/254 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.8861\nEpoch 47: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 623ms/step - loss: 0.2983 - accuracy: 0.8861 - val_loss: 0.4650 - val_accuracy: 0.8359 - lr: 1.0000e-07\nEpoch 48/150\n254/254 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.8924\nEpoch 48: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 622ms/step - loss: 0.2960 - accuracy: 0.8924 - val_loss: 0.4552 - val_accuracy: 0.8448 - lr: 1.0000e-07\nEpoch 49/150\n254/254 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8860\nEpoch 49: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 157s 619ms/step - loss: 0.2982 - accuracy: 0.8860 - val_loss: 0.4659 - val_accuracy: 0.8370 - lr: 1.0000e-07\nEpoch 50/150\n254/254 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.8835\nEpoch 50: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 159s 625ms/step - loss: 0.2995 - accuracy: 0.8835 - val_loss: 0.4851 - val_accuracy: 0.8315 - lr: 1.0000e-07\nEpoch 51/150\n254/254 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.8905\nEpoch 51: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 159s 624ms/step - loss: 0.2953 - accuracy: 0.8905 - val_loss: 0.4692 - val_accuracy: 0.8392 - lr: 1.0000e-07\nEpoch 52/150\n254/254 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.8819\nEpoch 52: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 620ms/step - loss: 0.3017 - accuracy: 0.8819 - val_loss: 0.4673 - val_accuracy: 0.8326 - lr: 1.0000e-07\nEpoch 53/150\n254/254 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.8867\nEpoch 53: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 157s 619ms/step - loss: 0.2965 - accuracy: 0.8867 - val_loss: 0.4693 - val_accuracy: 0.8459 - lr: 1.0000e-07\nEpoch 54/150\n254/254 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.8906\nEpoch 54: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 622ms/step - loss: 0.2975 - accuracy: 0.8906 - val_loss: 0.4625 - val_accuracy: 0.8415 - lr: 1.0000e-07\nEpoch 55/150\n254/254 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.8853\nEpoch 55: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 159s 625ms/step - loss: 0.3033 - accuracy: 0.8853 - val_loss: 0.4844 - val_accuracy: 0.8370 - lr: 1.0000e-07\nEpoch 56/150\n254/254 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.8867\nEpoch 56: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 620ms/step - loss: 0.2936 - accuracy: 0.8867 - val_loss: 0.4696 - val_accuracy: 0.8437 - lr: 1.0000e-07\nEpoch 57/150\n254/254 [==============================] - ETA: 0s - loss: 0.2970 - accuracy: 0.8869\nEpoch 57: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 623ms/step - loss: 0.2970 - accuracy: 0.8869 - val_loss: 0.4593 - val_accuracy: 0.8426 - lr: 1.0000e-07\nEpoch 58/150\n254/254 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.8879\nEpoch 58: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 620ms/step - loss: 0.3012 - accuracy: 0.8879 - val_loss: 0.4744 - val_accuracy: 0.8448 - lr: 1.0000e-07\nEpoch 59/150\n254/254 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.8897\nEpoch 59: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 159s 625ms/step - loss: 0.2978 - accuracy: 0.8897 - val_loss: 0.4892 - val_accuracy: 0.8304 - lr: 1.0000e-07\nEpoch 60/150\n254/254 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.8868\nEpoch 60: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 621ms/step - loss: 0.3020 - accuracy: 0.8868 - val_loss: 0.4827 - val_accuracy: 0.8326 - lr: 1.0000e-07\nEpoch 61/150\n254/254 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.8882\nEpoch 61: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 159s 624ms/step - loss: 0.2966 - accuracy: 0.8882 - val_loss: 0.4803 - val_accuracy: 0.8359 - lr: 1.0000e-07\nEpoch 62/150\n254/254 [==============================] - ETA: 0s - loss: 0.2946 - accuracy: 0.8877\nEpoch 62: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 621ms/step - loss: 0.2946 - accuracy: 0.8877 - val_loss: 0.4644 - val_accuracy: 0.8492 - lr: 1.0000e-07\nEpoch 63/150\n254/254 [==============================] - ETA: 0s - loss: 0.2966 - accuracy: 0.8904\nEpoch 63: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 622ms/step - loss: 0.2966 - accuracy: 0.8904 - val_loss: 0.4822 - val_accuracy: 0.8503 - lr: 1.0000e-07\nEpoch 64/150\n254/254 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.8860\nEpoch 64: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 621ms/step - loss: 0.2965 - accuracy: 0.8860 - val_loss: 0.4527 - val_accuracy: 0.8415 - lr: 1.0000e-07\nEpoch 65/150\n254/254 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.8828\nEpoch 65: val_accuracy did not improve from 0.85255\n254/254 [==============================] - 158s 623ms/step - loss: 0.3076 - accuracy: 0.8828 - val_loss: 0.4739 - val_accuracy: 0.8359 - lr: 1.0000e-07\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# MODEL EVALUATION","metadata":{}},{"cell_type":"code","source":"test_labels = test_batches.classes\ntest_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:08:21.553411Z","iopub.execute_input":"2024-01-13T10:08:21.553824Z","iopub.status.idle":"2024-01-13T10:08:21.560850Z","shell.execute_reply.started":"2024-01-13T10:08:21.553791Z","shell.execute_reply":"2024-01-13T10:08:21.559501Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(1002,)"},"metadata":{}}]},{"cell_type":"code","source":"model.load_weights('model.h5')\n# make a prediction\npredictions = model.predict(test_batches, steps=len(df_test), verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:11:49.110277Z","iopub.execute_input":"2024-01-13T10:11:49.110726Z","iopub.status.idle":"2024-01-13T10:14:12.175729Z","shell.execute_reply.started":"2024-01-13T10:11:49.110681Z","shell.execute_reply":"2024-01-13T10:14:12.174379Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"1002/1002 [==============================] - 112s 112ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"cm = confusion_matrix(test_labels, predictions.argmax(axis=1))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:14:12.178480Z","iopub.execute_input":"2024-01-13T10:14:12.179388Z","iopub.status.idle":"2024-01-13T10:14:12.186875Z","shell.execute_reply.started":"2024-01-13T10:14:12.179348Z","shell.execute_reply":"2024-01-13T10:14:12.185861Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:15:04.508265Z","iopub.execute_input":"2024-01-13T10:15:04.508729Z","iopub.status.idle":"2024-01-13T10:15:04.520863Z","shell.execute_reply.started":"2024-01-13T10:15:04.508695Z","shell.execute_reply":"2024-01-13T10:15:04.519530Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"test_batches.class_indices","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:15:08.168227Z","iopub.execute_input":"2024-01-13T10:15:08.168668Z","iopub.status.idle":"2024-01-13T10:15:08.176710Z","shell.execute_reply.started":"2024-01-13T10:15:08.168634Z","shell.execute_reply":"2024-01-13T10:15:08.175246Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"{'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}"},"metadata":{}}]},{"cell_type":"code","source":"cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n\nplot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:15:10.304148Z","iopub.execute_input":"2024-01-13T10:15:10.304553Z","iopub.status.idle":"2024-01-13T10:15:10.892856Z","shell.execute_reply.started":"2024-01-13T10:15:10.304522Z","shell.execute_reply":"2024-01-13T10:15:10.892002Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Confusion matrix, without normalization\n[[  8   2  13   0   8   2   0]\n [  2  33  10   2   4   0   0]\n [  0   1  79   1  15  14   0]\n [  0   0   2   8   1   1   0]\n [  0   0  15   3  66  27   0]\n [  1   7  28   2  47 586   0]\n [  0   1   1   0   2   0  10]]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Get the index of the class with the highest probability score\ny_pred = np.argmax(predictions, axis=1)\n\n# Get the labels of the test images.\ny_true = test_batches.classes","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:15:18.924764Z","iopub.execute_input":"2024-01-13T10:15:18.925215Z","iopub.status.idle":"2024-01-13T10:15:18.931120Z","shell.execute_reply.started":"2024-01-13T10:15:18.925179Z","shell.execute_reply":"2024-01-13T10:15:18.929668Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Generate a classification report\nreport = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n\nprint(report)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:21:21.663480Z","iopub.execute_input":"2024-01-13T10:21:21.663990Z","iopub.status.idle":"2024-01-13T10:21:21.683383Z","shell.execute_reply.started":"2024-01-13T10:21:21.663940Z","shell.execute_reply":"2024-01-13T10:21:21.682179Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n       akiec       0.73      0.24      0.36        33\n         bcc       0.75      0.65      0.69        51\n         bkl       0.53      0.72      0.61       110\n          df       0.50      0.67      0.57        12\n         mel       0.46      0.59      0.52       111\n          nv       0.93      0.87      0.90       671\n        vasc       1.00      0.71      0.83        14\n\n    accuracy                           0.79      1002\n   macro avg       0.70      0.64      0.64      1002\nweighted avg       0.81      0.79      0.79      1002\n\n","output_type":"stream"}]}]}